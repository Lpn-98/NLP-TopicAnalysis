{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import jieba  #处理中文\n",
    "import sklearn #分类器\n",
    "from sklearn.naive_bayes import MultinomialNB  #也可以换成伯努利或高斯的贝叶斯试试看\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gensim\n",
    "import jieba.analyse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim import models\n",
    "def tw_lda_get_tfidf(text,gamma=1.0):\n",
    "    #1.用正文+标题作为dictionary，过滤极端值\n",
    "    #--------------下面这里修改\n",
    "    content_and_title=[i.split(\" \") for i in text[\"微博正文(无标题切词后)\"]]\n",
    "    dictionary = gensim.corpora.Dictionary(content_and_title)\n",
    "    #-------------下面这里修改\n",
    "    dictionary.filter_extremes(no_below=15,no_above=0.8, keep_n=100000)\n",
    "    \n",
    "    #2.计算标题的tfidf\n",
    "    #--------------下面这里修改\n",
    "    processed_docs_title=[i.split(\" \") for i in text[\"标题(切词后)\"]]\n",
    "    bow_corpus_title = [dictionary.doc2bow(doc) for doc in processed_docs_title]\n",
    "    tfidf_title = models.TfidfModel(bow_corpus_title,normalize=False)\n",
    "    corpus_tfidf_title = tfidf_title[bow_corpus_title]\n",
    "#     print(\"corpus_tfidf_title\",corpus_tfidf_title)\n",
    "    \n",
    "    #3.计算正文+标题的tfidf\n",
    "    #--------------下面这里修改\n",
    "    processed_docs_content=[i.split(\" \") for i in text[\"微博正文(无标题切词后)\"]]\n",
    "    bow_corpus_content = [dictionary.doc2bow(doc) for doc in processed_docs_content]\n",
    "    tfidf_content = models.TfidfModel(bow_corpus_content,normalize=False)\n",
    "    corpus_tfidf_content = tfidf_content[bow_corpus_content]\n",
    "#     print(\"corpus_tfidf_content\",corpus_tfidf_content)\n",
    "    \n",
    "    #4.把标题和正文tfidf结合在一起\n",
    "    new_tfidf=[]\n",
    "    for i in range(len(corpus_tfidf_content)):#corpus_tfidf2[i]\n",
    "        dict_2={one:two for one,two in corpus_tfidf_content[i]}\n",
    "        dict_1={one:two for one,two in corpus_tfidf_title[i]}\n",
    "        for j in dict_1.keys():\n",
    "            if j in dict_2.keys():\n",
    "                dict_2[j]=(1-gamma)*dict_2[j]+gamma*dict_1[j]\n",
    "        new_tfidf_part=[(one,two) for one,two in sorted(dict_2.items(), key=lambda d: d[0],reverse=False)]\n",
    "#         print(\"new_tfidf_part\",new_tfidf_part)\n",
    "#        new_tfidf.append(new_tfidf_part)\n",
    "#        normed=gensim.models.tfidfmodel.smartirs_normalize(new_tfidf_part,\"c\")  #-------------这里改了把这个取消归一化了\n",
    "#        new_tfidf.append(normed)\n",
    "        new_tfidf.append(new_tfidf_part)\n",
    "    \n",
    "    #5.返回tfidf\n",
    "    return new_tfidf,dictionary\n",
    "\n",
    "\n",
    "# lda的模型\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import models\n",
    "\n",
    "def lda_and_coherence_score(processed_docs,num_topics,methods,corpus_tfidf_tw_lda=False,dictionary_tw_lda=False):\n",
    "    \n",
    "    if methods==\"tw_lda\":\n",
    "        dictionary=dictionary_tw_lda\n",
    "        corpus=corpus_tfidf_tw_lda\n",
    "    else:\n",
    "        dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "        dictionary.filter_extremes(no_below=15, no_above=0.8, keep_n=100000)\n",
    "        bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "        if methods==\"lda_normal\":\n",
    "            corpus=bow_corpus\n",
    "        elif methods==\"lda_tfidf\":\n",
    "            tfidf = models.TfidfModel(bow_corpus,normalize=False)#-----------------这里改了，改成false\n",
    "            corpus_tfidf = tfidf[bow_corpus]\n",
    "            corpus=corpus_tfidf\n",
    "    model = gensim.models.LdaMulticore(corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                                       passes=20,iterations=5000\n",
    "                                       #,eval_every=1\n",
    "                                      )\n",
    "    coherence = CoherenceModel(model=model, texts=processed_docs,dictionary=dictionary, coherence='c_v')\n",
    "    score = coherence.get_coherence()\n",
    "    logper=model.log_perplexity(corpus)\n",
    "    return model,score,logper\n",
    "\n",
    "\n",
    "#----------增加一步，算5次平均【def名中的10没改，但实际是算5次】\n",
    "def cs_bar_10(c,num_topics,methods,corpus_tfidf_tw_lda=False,dictionary_tw_lda=False):\n",
    "    cs_list=[]\n",
    "    logper_list=[]\n",
    "    if methods==\"tw_lda\":\n",
    "        for i in range(5):\n",
    "            lda,cs,logper=lda_and_coherence_score(c,num_topics,methods,corpus_tfidf_tw_lda=corpus_tfidf_tw_lda,dictionary_tw_lda=dictionary_tw_lda)\n",
    "            cs_list.append(cs)\n",
    "            logper_list.append(logper)\n",
    "    else:\n",
    "        for i in range(5):\n",
    "            lda,cs,logper=lda_and_coherence_score(c,num_topics,methods)\n",
    "            cs_list.append(cs)\n",
    "            logper_list.append(logper)\n",
    "#     cs_bar_10=sum(cs_list)/(len(cs_list)*1.0)               #----------------这里也改了\n",
    "#     logper_bar_10=sum(logper_list)/(len(logper_list)*1.0)   #----------------这里也改了\n",
    "    return lda,cs_list,logper_list                            #----------------这里也改了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=pd.read_csv(\"./huanqiu_news_with_title_2.csv\")\n",
    "#看text里有没有空值的项，因为split会发错误\n",
    "drop_na=[]\n",
    "for i in range(text.shape[0]):\n",
    "    if pd.isnull(text.loc[i]).any():\n",
    "        drop_na.append(i)\n",
    "\n",
    "text=text.drop(drop_na)\n",
    "text=text.reset_index(drop=True)\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline 标准lda和tfidf-lda\n",
    "\n",
    "有标题切词后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ba=time.process_time()\n",
    "topic_num=range(10,160,10)\n",
    "c=[i.split(\" \") for i in text[\"微博正文(有标题切词后)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_nor={}\n",
    "cs_nor_bar=[]\n",
    "\n",
    "logper_nor={}\n",
    "logper_nor_bar=[]\n",
    "\n",
    "cs_tf={}\n",
    "cs_tf_bar=[]\n",
    "\n",
    "logper_tf={}\n",
    "logper_tf_bar=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in topic_num:\n",
    "    starti=time.process_time()\n",
    "    num_topics=i\n",
    "    print(\"i\",i)\n",
    "    \n",
    "    lda1,cs1,logper1=cs_bar_10(c,num_topics,\"lda_normal\")\n",
    "    \n",
    "    cs_nor[i]=cs1\n",
    "    cs_nor_bar1=sum(cs1)/(len(cs1)*1.0) \n",
    "    cs_nor_bar.append(cs_nor_bar1)\n",
    "    \n",
    "    logper_nor[i]=logper1\n",
    "    logper_bar1=sum(logper1)/(len(logper1)*1.0)\n",
    "    logper_nor_bar.append(logper_bar1)\n",
    "    \n",
    "    \n",
    "    print(\"cs_nor\",cs1)\n",
    "    print(\"cs_nor_bar1\",cs_nor_bar1)\n",
    "    print(\"logper_nor\",logper1)\n",
    "    print(\"logper_bar1\",logper_bar1)\n",
    "    \n",
    "    \n",
    "    lda2,cs2,logper2=cs_bar_10(c,num_topics,\"lda_tfidf\")\n",
    "    \n",
    "    cs_tf[i]=cs2\n",
    "    cs_tf_bar2=sum(cs2)/(len(cs2)*1.0) \n",
    "    cs_tf_bar.append(cs_tf_bar2)\n",
    "    \n",
    "    logper_tf[i]=logper2\n",
    "    logper_bar2=sum(logper2)/(len(logper2)*1.0)\n",
    "    logper_tf_bar.append(logper_bar2)\n",
    "    \n",
    "    \n",
    "    print(\"cs_tf\",cs2)\n",
    "    print(\"cs_tf_bar2\",cs_tf_bar2)\n",
    "    print(\"logper_tf\",logper2)\n",
    "    print(\"logper_bar2\",logper_bar2)\n",
    "    \n",
    "    endi=time.process_time()\n",
    "    print('different for topic_num i:',i,'is',endi - starti)\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "    \n",
    "end_ba = time.process_time()\n",
    "print('different is %6.3f' % (end_ba - start_ba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cs_nor\")\n",
    "print(cs_nor)\n",
    "print(\"----------------\")\n",
    "print(\"logper_nor\")\n",
    "print(logper_nor)\n",
    "print(\"----------------\")\n",
    "print(\"cs_tf\")\n",
    "print(cs_tf)\n",
    "print(\"----------------\")\n",
    "print(\"logper_tf\")\n",
    "print(logper_tf)\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "my_font = font_manager.FontProperties(fname='C:/Windows/Fonts/simfang.ttf')\n",
    "\n",
    "plt.figure(figsize=(8,5),dpi=100)\n",
    "plt.plot(topic_num,cs_nor_bar,label=\"Cv_xLDA\",marker=\".\",linewidth=2)\n",
    "#plt.plot(topic_num,cs_tf_bar,label=\"Cv_tfidfLDA\",marker=\".\",linewidth=2)\n",
    "# plt.plot(topic_num,cs_tw_bar,label=\"cs_tw\",marker=\".\",linewidth=2)\n",
    "\n",
    "#new_ticks = np.linspace(3, 25, 23)\n",
    "#plt.xticks(new_ticks)\n",
    "plt.ylim(0.4, 0.55)\n",
    "\n",
    "plt.xlabel('TopicNum', fontproperties=my_font)\n",
    "plt.ylabel('ModelCoherenceScore', fontproperties=my_font)\n",
    "\n",
    "plt.legend(prop=my_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先求per再bar\n",
    "per_nor_bar=[]\n",
    "for i in topic_num:\n",
    "    per_nor_per=[2**((-1)*j) for j in logper_nor[i]]\n",
    "    temp_per_nor_per=sum(per_nor_per)/(len(per_nor_per)*1.0) \n",
    "    per_nor_bar.append(temp_per_nor_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "my_font = font_manager.FontProperties(fname='C:/Windows/Fonts/simfang.ttf')\n",
    "\n",
    "plt.figure(figsize=(8,5),dpi=100)\n",
    "plt.plot(topic_num,per_nor_bar,label=\"Perplexity_xLDA\",marker=\".\",linewidth=2)\n",
    "#plt.plot(topic_num,per_bar_tf,label=\"Perplexity_tfidfLDA\",marker=\".\",linewidth=2)\n",
    "# plt.plot(topic_num,cs_tw,label=\"cs_tw\",marker=\".\",linewidth=2)\n",
    "\n",
    "#new_ticks = np.linspace(3, 25, 23)\n",
    "#plt.xticks(new_ticks)\n",
    "#plt.ylim(0.0, 1.0)\n",
    "\n",
    "plt.xlabel('TopicNum', fontproperties=my_font)\n",
    "plt.ylabel('Perplexity', fontproperties=my_font)\n",
    "\n",
    "plt.legend(prop=my_font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从上面的图中选定topic_num后，进行tw的gamma测试\n",
    "\n",
    "（cs和perplexity中间选一个作为用来判断topic_num的）\n",
    "\n",
    "（记得把cs，per的结果列表保存好，放进txt里）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn=50 #把确定好的主题数放进这里\n",
    "c=[i.split(\" \") for i in text[\"微博正文(无标题切词后)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_gamma_1=time.process_time()\n",
    "gamma_l=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "cs_tw_dic={}\n",
    "cs_tw_bar=[]\n",
    "logper_tw_dic={}\n",
    "logper_tw_bar=[]\n",
    "\n",
    "for gamma in gamma_l:\n",
    "    start_gamma=time.process_time()\n",
    "    print(\"gamma\",gamma)\n",
    "    a,b=tw_lda_get_tfidf(text,gamma=gamma)\n",
    "\n",
    "    i=tn\n",
    "    num_topics=i\n",
    "    print(\"num_topics is:\",i)\n",
    "        \n",
    "    lda3,cs3,logper3=cs_bar_10(c,num_topics,\"tw_lda\",corpus_tfidf_tw_lda=a,dictionary_tw_lda=b)\n",
    "        \n",
    "    cs_tw_dic[gamma]=cs3\n",
    "    cs3_bar=sum(cs3)/(len(cs3)*1.0)\n",
    "    cs_tw_bar.append(cs3_bar)\n",
    "    print(\"cs_tw_list\",cs3)\n",
    "    print(\"cs3_bar\",cs3_bar)\n",
    "\n",
    "    logper_tw_dic[gamma]=logper3\n",
    "    logper3_bar=sum(logper3)/(len(logper3)*1.0)\n",
    "    logper_tw_bar.append(logper3_bar)\n",
    "    print(\"logper3\",logper3)\n",
    "    print(\"logper3_bar\",logper3_bar)\n",
    "\n",
    "    end_gamma=time.process_time()\n",
    "    print('different for gamma:',gamma,'is',end_gamma-start_gamma)\n",
    "    print(\"------------------\")\n",
    "        \n",
    "end_gamma_1=time.process_time()\n",
    "print('different for gamma(all):',gamma,'is',end_gamma_1-start_gamma_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画topicnum=50时，xLDA和tfidfLDA的Cv（这两个是定值，因此是水平的），不同gamma下TWLDA的大小\n",
    "plt.figure(figsize=(8,5),dpi=100)\n",
    "\n",
    "#cs_tw_bar[0]=0.4900683903696979\n",
    "\n",
    "plt.plot(list(cs_tw_dic.keys()),cs_tw_bar,label=\"Cv_TWLDA\",marker=\".\",linewidth=2)\n",
    "# for m,n in zip(list(cs_tw_dic.keys()),cs_tw_bar):\n",
    "#     plt.text(m+0.04, n+0.0015, round(n,5), ha='right', va= 'bottom',fontsize=8)\n",
    "\n",
    "plt.plot(list(cs_tw_dic.keys()),[cs_nor_bar[4] for i in range(11)],label=\"Cv_xLDA\",linewidth=2)\n",
    "m=gamma_l[0]\n",
    "n=cs_tw_bar[4]\n",
    "# plt.text(m+0.04, n-0.005, round(n,5), ha='right', va= 'bottom',fontsize=8)\n",
    "\n",
    "\n",
    "plt.plot(list(cs_tw_dic.keys()),[cs_tf_bar[4] for i in range(11)],label=\"Cv_tfidfLDA\",linewidth=2)\n",
    "m=gamma_l[0]\n",
    "n=cs_tf_bar[4]\n",
    "# plt.text(m+0.04, n-0.005, round(n,5), ha='right', va= 'bottom',fontsize=8)\n",
    "\n",
    "\n",
    "\n",
    "plt.ylim(0.45,0.55)\n",
    "plt.xlabel('Gamma', fontproperties=my_font)\n",
    "plt.ylabel('ModelCoherenceScore', fontproperties=my_font)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(prop=my_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##不需要----------\n",
    "##保存模型\n",
    "# from sklearn.externals import joblib\n",
    "# #将模型写入 model_joblib 文件\n",
    "# joblib.dump(lda3, 'twlda_lda3_model3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
