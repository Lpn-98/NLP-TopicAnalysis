{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import jieba  #处理中文\n",
    "import sklearn #分类器\n",
    "from sklearn.naive_bayes import MultinomialNB  #也可以换成伯努利或高斯的贝叶斯试试看\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gensim\n",
    "import jieba.analyse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim import models\n",
    "def tw_lda_get_tfidf(text,gamma=1.0):\n",
    "    #1.用正文+标题作为dictionary，过滤极端值\n",
    "    #--------------下面这里修改\n",
    "    content_and_title=[i.split(\" \") for i in text[\"微博正文(无标题切词后)\"]]\n",
    "    dictionary = gensim.corpora.Dictionary(content_and_title)\n",
    "    #-------------下面这里修改\n",
    "    dictionary.filter_extremes(no_below=15,no_above=0.8, keep_n=100000)\n",
    "    \n",
    "    #2.计算标题的tfidf\n",
    "    #--------------下面这里修改\n",
    "    processed_docs_title=[i.split(\" \") for i in text[\"标题(切词后)\"]]\n",
    "    bow_corpus_title = [dictionary.doc2bow(doc) for doc in processed_docs_title]\n",
    "    tfidf_title = models.TfidfModel(bow_corpus_title,normalize=False)\n",
    "    corpus_tfidf_title = tfidf_title[bow_corpus_title]\n",
    "#     print(\"corpus_tfidf_title\",corpus_tfidf_title)\n",
    "    \n",
    "    #3.计算正文+标题的tfidf\n",
    "    #--------------下面这里修改\n",
    "    processed_docs_content=[i.split(\" \") for i in text[\"微博正文(无标题切词后)\"]]\n",
    "    bow_corpus_content = [dictionary.doc2bow(doc) for doc in processed_docs_content]\n",
    "    tfidf_content = models.TfidfModel(bow_corpus_content,normalize=False)\n",
    "    corpus_tfidf_content = tfidf_content[bow_corpus_content]\n",
    "#     print(\"corpus_tfidf_content\",corpus_tfidf_content)\n",
    "    \n",
    "    #4.把标题和正文tfidf结合在一起\n",
    "    new_tfidf=[]\n",
    "    for i in range(len(corpus_tfidf_content)):#corpus_tfidf2[i]\n",
    "        dict_2={one:two for one,two in corpus_tfidf_content[i]}\n",
    "        dict_1={one:two for one,two in corpus_tfidf_title[i]}\n",
    "        for j in dict_1.keys():\n",
    "            if j in dict_2.keys():\n",
    "                dict_2[j]=(1-gamma)*dict_2[j]+gamma*dict_1[j]\n",
    "        new_tfidf_part=[(one,two) for one,two in sorted(dict_2.items(), key=lambda d: d[0],reverse=False)]\n",
    "#         print(\"new_tfidf_part\",new_tfidf_part)\n",
    "#        new_tfidf.append(new_tfidf_part)\n",
    "#        normed=gensim.models.tfidfmodel.smartirs_normalize(new_tfidf_part,\"c\")  #-------------这里改了把这个取消归一化了\n",
    "#        new_tfidf.append(normed)\n",
    "        new_tfidf.append(new_tfidf_part)\n",
    "    \n",
    "    #5.返回tfidf\n",
    "    return new_tfidf,dictionary\n",
    "\n",
    "\n",
    "# lda的模型\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import models\n",
    "\n",
    "def lda_and_coherence_score(processed_docs,num_topics,methods,corpus_tfidf_tw_lda=False,dictionary_tw_lda=False):\n",
    "    \n",
    "    if methods==\"tw_lda\":\n",
    "        dictionary=dictionary_tw_lda\n",
    "        corpus=corpus_tfidf_tw_lda\n",
    "    else:\n",
    "        dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "        dictionary.filter_extremes(no_below=15, no_above=0.8, keep_n=100000)\n",
    "        bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "        if methods==\"lda_normal\":\n",
    "            corpus=bow_corpus\n",
    "        elif methods==\"lda_tfidf\":\n",
    "            tfidf = models.TfidfModel(bow_corpus,normalize=False)#-----------------这里改了，改成false\n",
    "            corpus_tfidf = tfidf[bow_corpus]\n",
    "            corpus=corpus_tfidf\n",
    "    model = gensim.models.LdaMulticore(corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                                       passes=20,iterations=5000\n",
    "                                       #,eval_every=1\n",
    "                                      )\n",
    "    coherence = CoherenceModel(model=model, texts=processed_docs,dictionary=dictionary, coherence='c_v')\n",
    "    score = coherence.get_coherence()\n",
    "    logper=model.log_perplexity(corpus)\n",
    "    return model,score,logper\n",
    "\n",
    "\n",
    "#----------增加一步，算5次平均【def名中的10没改，但实际是算5次】\n",
    "def cs_bar_10(c,num_topics,methods,corpus_tfidf_tw_lda=False,dictionary_tw_lda=False):\n",
    "    cs_list=[]\n",
    "    logper_list=[]\n",
    "    if methods==\"tw_lda\":\n",
    "        for i in range(5):\n",
    "            lda,cs,logper=lda_and_coherence_score(c,num_topics,methods,corpus_tfidf_tw_lda=corpus_tfidf_tw_lda,dictionary_tw_lda=dictionary_tw_lda)\n",
    "            cs_list.append(cs)\n",
    "            logper_list.append(logper)\n",
    "    else:\n",
    "        for i in range(5):\n",
    "            lda,cs,logper=lda_and_coherence_score(c,num_topics,methods)\n",
    "            cs_list.append(cs)\n",
    "            logper_list.append(logper)\n",
    "#     cs_bar_10=sum(cs_list)/(len(cs_list)*1.0)               #----------------这里也改了\n",
    "#     logper_bar_10=sum(logper_list)/(len(logper_list)*1.0)   #----------------这里也改了\n",
    "    return lda,cs_list,logper_list                            #----------------这里也改了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text=pd.read_csv(\"./huanqiu_news_with_title_2.csv\")\n",
    "#看text里有没有空值的项，因为split会发错误\n",
    "drop_na=[]\n",
    "for i in range(text.shape[0]):\n",
    "    if pd.isnull(text.loc[i]).any():\n",
    "        drop_na.append(i)\n",
    "\n",
    "text=text.drop(drop_na)\n",
    "text=text.reset_index(drop=True)\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[i.split(\" \") for i in text[\"微博正文(有标题切词后)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn=50 #把确定好的主题数放进这里（和上一小节中的一致）\n",
    "ga=0.5#把确定好的gamma放进这里\n",
    "\n",
    "a,b=tw_lda_get_tfidf(text,gamma=ga)\n",
    "lda3,cs3,logper3=cs_bar_10(c,\n",
    "                           tn,\n",
    "                           \"tw_lda\",\n",
    "                           corpus_tfidf_tw_lda=a,\n",
    "                           dictionary_tw_lda=b)\n",
    "text_topics3=lda3.get_document_topics(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TW-LDA可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda3, a, b)\n",
    "\n",
    "end_lda = time.clock()\n",
    "\n",
    "#pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分主题看微博量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda3.print_topics(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_topics_dict3={}\n",
    "for i in range(tn):\n",
    "    text_topics_dict3[i]=[]\n",
    "    \n",
    "text_topics_no_dict3={}\n",
    "for i in range(tn):\n",
    "    text_topics_no_dict3[i]=[]\n",
    "\n",
    "for i in range(len(text_topics3)):\n",
    "    dict_text_topics3=dict(text_topics3[i])\n",
    "    #print(dict_text_topics3)\n",
    "    for key,value in dict_text_topics3.items():\n",
    "        if(value == max(dict_text_topics3.values()) and str(max(dict_text_topics3.values()))!=\"0.02\"):\n",
    "            text_topics_dict3[key].append(value)\n",
    "            text_topics_no_dict3[key].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda3.print_topics(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda3.show_topic(48,    #改变这个看不同主题,总结规律\n",
    "                      #（和上一小节好像差不多，看看是不是）\n",
    "                20)   #20个关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#编号为48的主题\n",
    "topic_id=48\n",
    "print(lda3.show_topic(topic_id,20))\n",
    "import re\n",
    "time_3={}\n",
    "for i in range(1,13):\n",
    "    month_text=0\n",
    "    if len(str(i))==1:\n",
    "        mon=\"0\"+str(i)\n",
    "    else:\n",
    "        mon=str(i)\n",
    "    month_re='2019-'+mon\n",
    "    time_list=text[\"发布时间\"][text_topics_no_dict3[topic_id]]\n",
    "    for j in time_list:\n",
    "        if month_re in j:\n",
    "            month_text=month_text+1\n",
    "    time_3[mon]=month_text\n",
    "print(time_3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "plt.figure(figsize=(13,5),dpi=50)\n",
    "\n",
    "month_re_list=[]\n",
    "for i in range(1,13):\n",
    "    if len(str(i))==1:\n",
    "        mon=\"0\"+str(i)\n",
    "    else:\n",
    "        mon=str(i)\n",
    "    month_re='2019-'+mon\n",
    "    month_re_list.append(month_re)\n",
    "month_re_list.append('2020-01')\n",
    "#print(\"month_re_list\",month_re_list)\n",
    "new_ticks =month_re_list\n",
    "\n",
    "plt.xticks(range(1,14),new_ticks)\n",
    "\n",
    "plt.ylim(0, 250)\n",
    "\n",
    "x = [int(i[0]) for i in time_3.items()]\n",
    "x.append(13)\n",
    "\n",
    "y = [int(i[1]) for i in time_3.items()]\n",
    "y.append(0)\n",
    "#np.linspace(0, 10, num=11, endpoint=True)\n",
    "\n",
    "f2 = interp1d(x, y, kind='zero')\n",
    "\n",
    "xnew = np.linspace(1, 13, num=1001, endpoint=False)\n",
    "#plt.plot(x, y, 'o')\n",
    "plt.plot(xnew, f2(xnew), '-',color='blue')\n",
    "plt.legend(['Topic1', 'zero'], loc='best')\n",
    "\n",
    "x1=[int(i[0]) for i in time_3.items()]\n",
    "y1=[int(i[1]) for i in time_3.items()]\n",
    "\n",
    "for m,n in zip(x1,y1):\n",
    "    plt.text(m+0.5, n+0.15, '%.0f' % n, ha='right', va= 'bottom',fontsize=11)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
