{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,\\\n",
    "                                                TfidfVectorizer\n",
    "\n",
    "def train_predict_evaluate_model(classifier, train_features, train_labels,\n",
    "                                 test_features, test_labels):\n",
    "    \"\"\"\n",
    "    训练、预测、评估 模型\n",
    "    :param classifier: 模型\n",
    "    :param train_features: 训练集特征\n",
    "    :param train_labels: 训练集label\n",
    "    :param test_features: 测试集特征\n",
    "    :param test_labels: 测试集label\n",
    "    :return: 预测结果\n",
    "    \"\"\"\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    predictions = classifier.predict(test_features)\n",
    "    get_metrics(true_labels=test_labels, predicted_labels=predictions)\n",
    "    return predictions\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    分别计算预测结果的准确率、精确率、召回率、F1值，直接打印出这些结果\n",
    "    :param true_labels: 真实label\n",
    "    :param predicted_labels: 预测结果\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"accuracy:\", np.round(metrics.accuracy_score(true_labels,\n",
    "                                                       predicted_labels), 5))\n",
    "    print(\"precision:\", np.round(metrics.precision_score(\n",
    "        true_labels, predicted_labels, average='weighted'), 5))\n",
    "    print(\"recall:\", np.round(metrics.recall_score(\n",
    "        true_labels, predicted_labels, average='weighted'), 5))\n",
    "    print(\"f1 score:\", np.round(metrics.f1_score(\n",
    "        true_labels, predicted_labels, average='weighted'), 5))\n",
    "\n",
    "def xishu2choumi(corpus):\n",
    "    data = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "    line_count = 0\n",
    "    for line in corpus:  # lsi_corpus_total 是之前由gensim生成的lsi向量\n",
    "        for elem in line:\n",
    "            rows.append(line_count)\n",
    "            cols.append(elem[0])\n",
    "            data.append(elem[1])\n",
    "        line_count += 1\n",
    "    lsi_sparse_matrix = scipy.sparse.csr_matrix((data,(rows,cols))) # 稀疏向量\n",
    "    corpus2matrix = lsi_sparse_matrix.toarray()  # 密集向量\n",
    "    return corpus2matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "text=pd.read_csv(\"./test_news_with_title_2.csv\")\n",
    "#看text里有没有空值的项，因为split会发错误\n",
    "drop_na=[]\n",
    "for i in range(text.shape[0]):\n",
    "    if pd.isnull(text.loc[i]).any():\n",
    "        drop_na.append(i)\n",
    "\n",
    "text=text.drop(drop_na)\n",
    "text=text.reset_index(drop=True)\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(text.shape[0]):\n",
    "    if \"香港\" in text[\"微博正文(有标题切词后)\"][i]:\n",
    "        print(i)\n",
    "        print(text.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.BOW+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_(processed_docs):\n",
    "    dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.8, keep_n=100000)\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "    return bow_corpus\n",
    "\n",
    "text_splited=[i.split(\" \") for i in text[\"微博正文(有标题切词后)\"]]\n",
    "bow_corpus=bow_(text_splited)\n",
    "#print(bow_corpus)\n",
    "\n",
    "bow_matrix=xishu2choumi(bow_corpus)\n",
    "#print(bow_matrix)\n",
    "\n",
    "train_matrix, test_matrix, y_train, y_test= train_test_split(bow_matrix, text[\"分类\"],random_state=2,test_size=0.2)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_matrix,y_train)\n",
    "predictions = clf.predict(test_matrix)\n",
    "get_metrics(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.TFIDF+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_(processed_docs):\n",
    "    dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.8, keep_n=100000)\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "    tfidf = models.TfidfModel(bow_corpus,normalize=False)#-----------------这里改了，改成false\n",
    "    corpus_tfidf = tfidf[bow_corpus]\n",
    "    return corpus_tfidf\n",
    "\n",
    "text_splited=[i.split(\" \") for i in text[\"微博正文(有标题切词后)\"]]\n",
    "tfidf_corpus=tfidf_(text_splited)\n",
    "#print(tfidf_corpus)\n",
    "\n",
    "tfidf_matrix=xishu2choumi(tfidf_corpus)\n",
    "#print(tfidf_matrix)\n",
    "\n",
    "train_matrix, test_matrix, y_train, y_test= train_test_split(tfidf_matrix, text[\"分类\"],random_state=2,test_size=0.2)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_matrix,y_train)\n",
    "predictions = clf.predict(test_matrix)\n",
    "get_metrics(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. W-TFIDF+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tw_lda_get_tfidf(text,gamma):\n",
    "    #1.用正文+标题作为dictionary，过滤极端值\n",
    "    #--------------下面这里修改\n",
    "    content_and_title=[i.split(\" \") for i in text[\"微博正文(有标题切词后)\"]]\n",
    "    dictionary = gensim.corpora.Dictionary(content_and_title)\n",
    "    #-------------下面这里修改\n",
    "    dictionary.filter_extremes(no_below=15,no_above=0.8, keep_n=100000)\n",
    "    \n",
    "    #2.计算标题的tfidf\n",
    "    #--------------下面这里修改\n",
    "    processed_docs_title=[i.split(\" \") for i in text[\"标题(切词后)\"]]\n",
    "    bow_corpus_title = [dictionary.doc2bow(doc) for doc in processed_docs_title]\n",
    "    tfidf_title = models.TfidfModel(bow_corpus_title,normalize=False)\n",
    "    corpus_tfidf_title = tfidf_title[bow_corpus_title]\n",
    "#     print(\"corpus_tfidf_title\",corpus_tfidf_title)\n",
    "    \n",
    "    #3.计算正文+标题的tfidf\n",
    "    #--------------下面这里修改\n",
    "    processed_docs_content=[i.split(\" \") for i in text[\"微博正文(有标题切词后)\"]]\n",
    "    bow_corpus_content = [dictionary.doc2bow(doc) for doc in processed_docs_content]\n",
    "    tfidf_content = models.TfidfModel(bow_corpus_content,normalize=False)\n",
    "    corpus_tfidf_content = tfidf_content[bow_corpus_content]\n",
    "#     print(\"corpus_tfidf_content\",corpus_tfidf_content)\n",
    "    \n",
    "    #4.把标题和正文tfidf结合在一起\n",
    "    new_tfidf=[]\n",
    "    for i in range(len(corpus_tfidf_content)):#corpus_tfidf2[i]\n",
    "        dict_2={one:two for one,two in corpus_tfidf_content[i]}\n",
    "        dict_1={one:two for one,two in corpus_tfidf_title[i]}\n",
    "        for j in dict_1.keys():\n",
    "            if j in dict_2.keys():\n",
    "                dict_2[j]=(1-gamma)*dict_2[j]+gamma*dict_1[j]\n",
    "        new_tfidf_part=[(one,two) for one,two in sorted(dict_2.items(), key=lambda d: d[0],reverse=False)]\n",
    "#         print(\"new_tfidf_part\",new_tfidf_part)\n",
    "#        new_tfidf.append(new_tfidf_part)\n",
    "#        normed=gensim.models.tfidfmodel.smartirs_normalize(new_tfidf_part,\"c\")  #-------------这里改了把这个取消归一化了\n",
    "#        new_tfidf.append(normed)\n",
    "        new_tfidf.append(new_tfidf_part)\n",
    "    \n",
    "    #5.返回tfidf\n",
    "    return new_tfidf,dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtfidf_svm(text,gamma):\n",
    "    a,b=tw_lda_get_tfidf(text,gamma=gamma)\n",
    "\n",
    "    wtfidf_matrix=xishu2choumi(a)\n",
    "    #print(bow_matrix)\n",
    "\n",
    "    train_matrix, test_matrix, y_train, y_test= train_test_split(wtfidf_matrix, text[\"分类\"],random_state=2,test_size=0.2)\n",
    "\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_matrix,y_train)\n",
    "    \n",
    "    predictions = clf.predict(train_matrix)\n",
    "    get_metrics(true_labels=y_train, predicted_labels=predictions)\n",
    "    \n",
    "    print(\"++++++++++\")\n",
    "    \n",
    "    predictions = clf.predict(test_matrix)\n",
    "    get_metrics(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ga in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    print(ga)\n",
    "    wtfidf_svm(text,ga)\n",
    "    print(\"--------------\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "my_font = font_manager.FontProperties(fname='C:/Windows/Fonts/simfang.ttf')\n",
    "\n",
    "\n",
    "f1_wtfidf={0.0:0.85381,0.1:0.85668,0.2:0.85464,0.3:0.85481,0.4:0.85589,0.5:0.85706,0.6:0.85994,0.7:0.85884,0.8:0.85705,0.9:0.84846,1.0:0.84365}\n",
    "f1_wtfidf_values=[i for i in f1_wtfidf.values()]\n",
    "f1_wtfidf_keys=[i for i in f1_wtfidf.keys()]\n",
    "\n",
    "f1_bow=[0.6674 for i in range(len(f1_wtfidf_keys))]\n",
    "f1_tfidf=[0.7998 for i in range(len(f1_wtfidf_keys))]\n",
    "\n",
    "plt.figure(figsize=(8,5),dpi=100)\n",
    "plt.plot(f1_wtfidf_keys,f1_wtfidf_values,label=\"WTFIDF+SVM_F1_Score\",marker=\".\",linewidth=2)\n",
    "# plt.plot(f1_wtfidf_keys,f1_bow,label=\"BOW+SVM_F1_Score\",linewidth=2)\n",
    "# plt.plot(f1_wtfidf_keys,f1_tfidf,label=\"TFIDF+SVM_F1_Score\",linewidth=2)\n",
    "\n",
    "\n",
    "plt.ylim(0.8,0.9)\n",
    "plt.xlabel('Gamma', fontproperties=my_font)\n",
    "plt.ylabel('ModelF1Score', fontproperties=my_font)\n",
    "plt.legend(prop=my_font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
